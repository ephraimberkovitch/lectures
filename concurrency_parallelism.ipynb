{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1549a6",
   "metadata": {},
   "source": [
    "# Concurrency and Parallelism in Python\n",
    "\n",
    "\n",
    "## CPU\n",
    "* parallel execution - tasks execute on multiple CPUs at the same time\n",
    "* concurrent execution - only one task runs at one time on a single CPU, however, making progress simultaneously\n",
    "\n",
    "## Memory\n",
    "* each process created by a Parent process has its separate memory\n",
    "* threads spawned by a process \n",
    "  * share memory space and other OS resources with other threads, consuming less memory than processes do.\n",
    "    * code section\n",
    "    * data section\n",
    "  * each thread has its own \n",
    "    * thread ID, \n",
    "    * a program counter, \n",
    "    * a register set, \n",
    "    * and a stack. \n",
    "\n",
    "## Inter-Process Communication and Locks\n",
    "* Since **processes** have different memory segments, a _communication channel_ is required to pass data between them\n",
    "* **Threads** - because of shared resources, we need to use _locks_ to avoid the _race condition_. A race condition occurs when shared data is accessed and manipulated concurrently. However, using locks make sure that only one thread manipulates the data at one time. For a thread to manipulate the shared data, it has to acquire the lock. During that time, if some other thread tries to acquire the lock, it will have to wait until the lock gets released.\n",
    "\n",
    "## GIL\n",
    "Programs in Python are single-threaded and use a single CPU because of the Global Interpreter Lock or GIL. It is a lock that only allows one thread to hold control of the Python interpreter, and thus only one thread gets executed at a time. Therefore, Python cannot use multiprocessing automatically. However, the multiprocessing module solves this problem by bypassing the GIL.\n",
    "\n",
    "In multiprocessing, each process has a separate GIL and instance of a Python interpreter. However, in multithreading, all the threads have a single GIL and thus one Python interpreter. Therefore, only one thread can be executed at one time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64d2c8",
   "metadata": {},
   "source": [
    "## Performance\n",
    "* I/O bound task - utilizes most of its time performing I/O operations\n",
    "* CPU bound task - requires the CPU mostly to complete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee5b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as f\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da35d620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU-bound task\n",
    "def cpu_bound(x):\n",
    "    count = 0\n",
    "    for i in range(0, x**x):\n",
    "      count += 1\n",
    "    return count\n",
    "cpu_bound(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cc3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 20.169926166534424 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multi-processing\n",
    "from multiprocessing import Process\n",
    "\n",
    "starttime = time.time()\n",
    "processlist = []\n",
    "for i in range(0, 4):\n",
    "    process = Process(target=f.cpu_bound, args=(9,))\n",
    "    processlist.append(process)\n",
    "    process.start()\n",
    "\n",
    "for process in processlist:\n",
    "    process.join()\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a4953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387420489, 387420489, 387420489, 387420489]\n",
      "Time taken 21.96160912513733 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multi-processing - another way\n",
    "from multiprocessing import Pool\n",
    "\n",
    "starttime = time.time()\n",
    "with Pool(4) as p:\n",
    "    print(p.map(f.cpu_bound, [9, 9, 9, 9]))\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffca8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 76.61669826507568 seconds\n"
     ]
    }
   ],
   "source": [
    "# Single Processing and Threading\n",
    "starttime = time.time()\n",
    "for i in range(0, 4):\n",
    "    f.cpu_bound(9)\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d420db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 74.9468080997467 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multi-threading\n",
    "import threading\n",
    "\n",
    "starttime = time.time()\n",
    "threads = []\n",
    "for i in range(0, 4):\n",
    "    thread = threading.Thread(target=f.cpu_bound, args=(9,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dcf59d",
   "metadata": {},
   "source": [
    "## CPU Bound Tasks - Conclusions\n",
    "* multiprocessing < serial execution <= multithreading\n",
    "  * in multiprocessing, processes run in parallel and utilize multiple CPUs. Since our code requires CPU most of the time, multiprocessing gives better results. \n",
    "  * However, in multithreading, only one thread runs at one time. Because there is no blocking due to any I/O operation, the CPU does not remain idle. Hence, it almost gives the same performance as serial execution does.\n",
    "  * there is also an overhead of switching between the threads, which is not in serial execution. Thus, serial execution performs better than multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4b6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O-bound task\n",
    "def io_bound(i):\n",
    "    file_name = \"file\" + str(i) + \".txt\"\n",
    "    f = open(file_name, \"w\")\n",
    "    print(\"writing to a file\")\n",
    "    for j in range(0, 8 ** 8):\n",
    "        f.write(\"This is a sample text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ee1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "Time taken 3.2585530281066895 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multi-processing\n",
    "from multiprocessing import Process\n",
    "\n",
    "starttime = time.time()\n",
    "processlist = []\n",
    "for i in range(0, 4):\n",
    "    process = Process(target=f.io_bound, args=(i,))\n",
    "    processlist.append(process)\n",
    "    process.start()\n",
    "\n",
    "for process in processlist:\n",
    "    process.join()\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6efe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "Time taken 8.330154180526733 seconds\n"
     ]
    }
   ],
   "source": [
    "# Uniprocessing and Single threading\n",
    "starttime = time.time()\n",
    "for i in range(0, 4):\n",
    "    f.io_bound(i)\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a09989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "writing to a file\n",
      "Time taken 7.467015027999878 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multi-threading\n",
    "starttime = time.time()\n",
    "threads = []\n",
    "for i in range(0, 4):\n",
    "    thread = threading.Thread(target=f.io_bound, args=(i,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "endtime = time.time()\n",
    "print(f\"Time taken {endtime-starttime} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d2457",
   "metadata": {},
   "source": [
    "## I/O-Bound Tasks Conclusions\n",
    "* When an I/O operation comes up in serial execution, the CPU remains idle and that thread blocks. Hence, no activity is done on the part of that process until that operation gets completed. \n",
    "* However, in multithreading, GIL releases the lock, and some other thread acquires it and starts running. That is why multithreading performs better than serial execution. Moreover, the overhead of creating a process is more than creating a thread. Therefore, multithreading performs better than multiprocessing, in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098adde",
   "metadata": {},
   "source": [
    "**So, use multithreading when tasks include I/O operations or network requests mostly, and use multiprocessing when you have CPU intensive tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001f831",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Multi-threading</th>\n",
    "        <th>Multi-processing</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Only uses a single CPU</td>\n",
    "        <td>Uses multiple CPUs or cores</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Thread creation is faster than process creation, i.e., less overhead</td>\n",
    "        <td>Process creation is slower</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Concurrent Execution</td>\n",
    "        <td>Parallel Execution</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Threads have the same memory space</td>\n",
    "        <td>Processes have a separate memory space</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Requires locks to handle shared data</td>\n",
    "        <td>It does not require locks as threads do because the memory space is different unless you explicitly use some shared resource</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>One GIL</td>\n",
    "        <td>Each process has a separate GIL</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>No communication channel is required</td>\n",
    "        <td>Processes require a communication channel for IPC</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Context switching between threads is faster than processes</td>\n",
    "        <td>Context switching is slower</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Suitable for I/O bound and network bound tasks</td>\n",
    "        <td>Suitable for CPU bound tasks</td>\n",
    "    </tr>\n",
    "<table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd082058",
   "metadata": {},
   "source": [
    "## Coroutines and asyncio\n",
    "\n",
    "**single-threaded, single-process design: it uses cooperative multitasking**\n",
    "\n",
    "* Asynchronous routines are able to “pause” while waiting on their ultimate result and let other routines run in the meantime.\n",
    "* Asynchronous code facilitates concurrent execution - gives the look and feel of concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b9727",
   "metadata": {},
   "source": [
    "![title](img/asyncio.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d21048",
   "metadata": {},
   "source": [
    "Chess master Judit Polgár hosts a chess exhibition in which she plays multiple amateur players. She has two ways of conducting the exhibition: synchronously and asynchronously.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "24 opponents\n",
    "Judit makes each chess move in 5 seconds\n",
    "Opponents each take 55 seconds to make a move\n",
    "Games average 30 pair-moves (60 moves total)\n",
    "Synchronous version: Judit plays one game at a time, never two at the same time, until the game is complete. Each game takes (55 + 5) * 30 == 1800 seconds, or 30 minutes. The entire exhibition takes 24 * 30 == 720 minutes, or 12 hours.\n",
    "\n",
    "Asynchronous version: Judit moves from table to table, making one move at each table. She leaves the table and lets the opponent make their next move during the wait time. One move on all 24 games takes Judit 24 * 5 == 120 seconds, or 2 minutes. The entire exhibition is now cut down to 120 * 30 == 3600 seconds, or just 1 hour.\n",
    "\n",
    "**Async IO** takes long waiting periods in which functions would otherwise be blocking and allows other functions to run during that downtime. (A function that blocks effectively forbids others from running from the time that it starts until the time that it returns.)\n",
    "\n",
    "**coroutine** is a specialized version of a Python generator function (function that can suspend its execution before reaching return, and it can indirectly pass control to another coroutine for some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0911bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "One\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Two\n",
      "Executed in 1.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_count():  # native coroutine\n",
    "    print(\"One\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "async def async_main():\n",
    "    await asyncio.gather(count(), count(), count())\n",
    "\n",
    "s = time.perf_counter()\n",
    "await async_main()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(f\"Executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5ab96b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "One\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Executed in 3.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "def sync_count():\n",
    "    print(\"One\")\n",
    "    time.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "def sync_main():\n",
    "    for _ in range(3):\n",
    "        sync_count()\n",
    "\n",
    "s = time.perf_counter()\n",
    "sync_main()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(f\"Executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8feb3b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "One\n",
      "One\n",
      "TwoTwo\n",
      "\n",
      "Two\n",
      "Executed in 1.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "def threading_count():\n",
    "    print(\"One\")\n",
    "    time.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "def threading_main():\n",
    "    thread1 = threading.Thread(target=threading_count)\n",
    "    thread2 = threading.Thread(target=threading_count)\n",
    "    thread3 = threading.Thread(target=threading_count)\n",
    "    \n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    thread3.start()\n",
    "    \n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    thread3.join()\n",
    "\n",
    "s = time.perf_counter()\n",
    "threading_main()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(f\"Executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518433d1",
   "metadata": {},
   "source": [
    "## Multi-threading vs asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6b27ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call 1st API\n",
      "1st API finish\n",
      "call 2st API\n",
      "2nd API finish\n",
      "7.005630016326904\n"
     ]
    }
   ],
   "source": [
    "# Sequential code\n",
    "def sync_api1():\n",
    "    print(\"call 1st API\")\n",
    "    time.sleep(4)\n",
    "    print(\"1st API finish\")\n",
    "  \n",
    "def sync_api2():\n",
    "    print(\"call 2st API\")\n",
    "    time.sleep(3)\n",
    "    print(\"2nd API finish\")\n",
    "\n",
    "start = time.time()\n",
    "sync_api1()\n",
    "sync_api2()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4ab7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call 1st API\n",
      "call 2st API\n",
      "2nd API finish\n",
      "1st API finish\n",
      "4.006623268127441\n"
     ]
    }
   ],
   "source": [
    "# Multi-threaded code\n",
    "\n",
    "def threaded_api1():\n",
    "    print(\"call 1st API\")\n",
    "    time.sleep(4)\n",
    "    print(\"1st API finish\")\n",
    "  \n",
    "def threaded_api2():\n",
    "    print(\"call 2st API\")\n",
    "    time.sleep(3)\n",
    "    print(\"2nd API finish\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# create threads\n",
    "t1 = threading.Thread(target=threaded_api1, name='t1')\n",
    "t2 = threading.Thread(target=threaded_api2, name='t2')  \n",
    "\n",
    "# start threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# wait untill all threads finished\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f7350b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call 1st API\n",
      "call 2st API\n",
      "2nd API finish\n",
      "1st API finish\n",
      "4.003184795379639\n"
     ]
    }
   ],
   "source": [
    "# Async IO = non-blocking IO, using event loop\n",
    "async def async_api1():\n",
    "    print(\"call 1st API\")\n",
    "    await asyncio.sleep(4)\n",
    "    print(\"1st API finish\")\n",
    "  \n",
    "async def async_api2():\n",
    "    print(\"call 2st API\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"2nd API finish\")\n",
    "    \n",
    "start = time.time()\n",
    "# await async_api1()\n",
    "# await async_api2()\n",
    "await asyncio.gather(async_api1(), async_api2())\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cf0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}